{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# General\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To avoid Type3 fonts in generated pdf file\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "# Enable automatic module reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load PyALCS module\n",
    "from lcs.agents.acs2 import ACS2, Configuration, ClassifiersList\n",
    "\n",
    "# Load environments\n",
    "import gym\n",
    "import gym_maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment - Maze\n",
    "\n",
    "We are going to look at provided mazes. Their names starts with “Maze…” or “Woods…” so see what is possible to load :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Custom function for obtaining available environments\n",
    "filter_envs = lambda env: env.id.startswith(\"Maze\") or env.id.startswith(\"Woods\") or env.id.startswith(\"Test\") or env.id.startswith(\"Littman\") or env.id.startswith(\"Miyazaki\")\n",
    "\n",
    "all_envs = [env for env in gym.envs.registry.all()]\n",
    "maze_envs = [env for env in all_envs if filter_envs(env)]\n",
    "\n",
    "for env in maze_envs:\n",
    "    print(\"Maze ID: [{}], non-deterministic: [{}], trials: [{}]\".format(\n",
    "            env.id, env.nondeterministic, env.trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how it looks in action. First we are going to initialize new environment using gym.make() instruction from OpenAI Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MAZE = \"Woods14-v0\"\n",
    "\n",
    "# Initialize environment\n",
    "maze = gym.make(MAZE)\n",
    "\n",
    "# Reset it, by putting an agent into random position\n",
    "situation = maze.reset()\n",
    "\n",
    "# Render the state in ASCII\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reset() function puts an agent into random position (on path inside maze) returning current perception.\n",
    "\n",
    "The perception consists of 8 values representing N, NE, E, SE, S, SW, W, NW directions. \n",
    "\n",
    "It outputs 0 for the path, 1 for the wall and 9 for the reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show current agents perception\n",
    "situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interact with the environment by performing actions.\n",
    "\n",
    "Agent can perform 8 actions - moving into different directions.\n",
    "\n",
    "To do so use step(action) function. It will return couple interesting information: \n",
    "\n",
    "    - new state percepton, \n",
    "    - reward for executing move (ie. finding the reward) \n",
    "    - is the trial finish, \n",
    "    - debug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ACTION = 0 # Move N\n",
    "\n",
    "# Execute action\n",
    "state, reward, done, _ = maze.step(ACTION)\n",
    "\n",
    "# Show new state\n",
    "print(f\"New state: {state}, reward: {reward}, is done: {done}\")\n",
    "\n",
    "# Render the env one more time after executing step\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent - ACS2\n",
    "\n",
    "First provide a helper method for calculating obtained knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _maze_knowledge(population, environment) -> float:\n",
    "    transitions = environment.env.get_all_possible_transitions()\n",
    "\n",
    "    # Take into consideration only reliable classifiers\n",
    "    reliable_classifiers = [c for c in population if c.is_reliable()]\n",
    "\n",
    "    # Count how many transitions are anticipated correctly\n",
    "    nr_correct = 0\n",
    "\n",
    "    # For all possible destinations from each path cell\n",
    "    for start, action, end in transitions:\n",
    "\n",
    "        p0 = environment.env.maze.perception(*start)\n",
    "        p1 = environment.env.maze.perception(*end)\n",
    "\n",
    "        if any([True for cl in reliable_classifiers\n",
    "                if cl.predicts_successfully(p0, action, p1)]):\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / len(transitions) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lcs.metrics import population_metrics\n",
    "\n",
    "def _maze_metrics(pop, env):\n",
    "    metrics = {\n",
    "        'knowledge': _maze_knowledge(pop, env)\n",
    "    }\n",
    "\n",
    "    # Add basic population metrics\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CLASSIFIER_LENGTH=8\n",
    "NUMBER_OF_POSSIBLE_ACTIONS=8\n",
    "\n",
    "# Define agent's default configuration\n",
    "cfg = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_ga=False,\n",
    "    do_subsumption=True,\n",
    "    do_action_planning=False,\n",
    "    action_planning_frequency=50,\n",
    "    beta=0.05,\n",
    "    gamma=0.95,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.5,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8\n",
    ")\n",
    "\n",
    "# Define agent\n",
    "agent = ACS2(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "population, metrics = agent.explore(maze, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a sneak peek into a created list of classifiers. Let’s have a look at top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "population.sort(key=lambda cl: -cl.fitness)\n",
    "\n",
    "for cl in population[:100]:\n",
    "    #print(\"{!r} \\tq: {:.2f} \\tr: {:.2f} \\tir: {:.2f}\".format(cl, cl.q, cl.r, cl.ir))\n",
    "    print(\"{!r} \\t {!r} \\t {!r} \\t {:.3f} \\t {!r}\".format(cl.condition, cl.action, cl.effect, cl.fitness, cl.mark))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploitation\n",
    "\n",
    "Now we can either reuse our previous agent or initialize it one more time passing the initial population of classifiers as apriori knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reinitialize agent using defined configuration and population\n",
    "agent = ACS2(cfg, population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "population, metrics = agent.exploit(maze, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_metrics_to_df(explore_metrics, exploit_metrics):\n",
    "    def extract_details(row):\n",
    "        row['trial'] = row['trial']\n",
    "        row['steps'] = row['steps_in_trial']\n",
    "        row['numerosity'] = row['numerosity']\n",
    "        row['reliable'] = row['reliable']\n",
    "        row['knowledge'] = row['knowledge']\n",
    "        return row\n",
    "\n",
    "    # Load both metrics into data frame\n",
    "    explore_df = pd.DataFrame(explore_metrics)\n",
    "    exploit_df = pd.DataFrame(exploit_metrics)\n",
    "\n",
    "    # Mark them with specific phase\n",
    "    explore_df['phase'] = 'explore'\n",
    "    exploit_df['phase'] = 'exploit'\n",
    "\n",
    "    # Extract details\n",
    "    explore_df = explore_df.apply(extract_details, axis=1)\n",
    "    exploit_df = exploit_df.apply(extract_details, axis=1)\n",
    "\n",
    "    # Adjuts exploit trial counter\n",
    "    exploit_df['trial'] = exploit_df.apply(lambda r: r['trial']+len(explore_df), axis=1)\n",
    "\n",
    "    # Concatenate both dataframes\n",
    "    df = pd.concat([explore_df, exploit_df])\n",
    "    df.set_index('trial', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For various mazes visualize - classifiers / reliable classifiers for steps - optimal policy - steps (exploration | exploitation) - knowledge - parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_best_classifier(population, situation, cfg):\n",
    "    match_set = population.form_match_set(situation)\n",
    "    anticipated_change_cls = [cl for cl in match_set if cl.does_anticipate_change()]\n",
    "\n",
    "    if (len(anticipated_change_cls) > 0):\n",
    "        return max(anticipated_change_cls, key=lambda cl: cl.fitness)\n",
    "\n",
    "    return None\n",
    "\n",
    "def build_fitness_matrix(env, population, cfg):\n",
    "    original = env.env.maze.matrix\n",
    "    fitness = original.copy()\n",
    "\n",
    "    # Think about more 'functional' way of doing this\n",
    "    for index, x in np.ndenumerate(original):\n",
    "        # Path - best classfier fitness\n",
    "        if x == 0:\n",
    "            perception = env.env.maze.perception(index[1], index[0])\n",
    "            best_cl = find_best_classifier(population, perception, cfg)\n",
    "            if best_cl:\n",
    "                fitness[index] = best_cl.fitness\n",
    "            else:\n",
    "                fitness[index] = -1\n",
    "\n",
    "        # Wall - fitness = 0\n",
    "        if x == 1:\n",
    "            fitness[index] = 0\n",
    "\n",
    "        # Reward - inf fitness\n",
    "        if x == 9:\n",
    "            fitness[index] = fitness.max () + 500\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def build_action_matrix(env, population, cfg):\n",
    "    ACTION_LOOKUP = {\n",
    "        0: u'↑', 1: u'↗', 2: u'→', 3: u'↘',\n",
    "        4: u'↓', 5: u'↙', 6: u'←', 7: u'↖'\n",
    "    }\n",
    "\n",
    "    original = env.env.maze.matrix\n",
    "    action = original.copy().astype(str)\n",
    "\n",
    "    # Think about more 'functional' way of doing this\n",
    "    for index, x in np.ndenumerate(original):\n",
    "        # Path - best classfier fitness\n",
    "        if x == 0:\n",
    "            perception = env.env.maze.perception(index[1], index[0])\n",
    "            best_cl = find_best_classifier(population, perception, cfg)\n",
    "            if best_cl:\n",
    "                action[index] = ACTION_LOOKUP[best_cl.action]\n",
    "            else:\n",
    "                action[index] = '?'\n",
    "\n",
    "        # Wall - fitness = 0\n",
    "        if x == 1:\n",
    "            action[index] = '\\#'\n",
    "\n",
    "        # Reward - inf fitness\n",
    "        if x == 9:\n",
    "            action[index] = 'R'\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting functions and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot constants\n",
    "TITLE_TEXT_SIZE=18\n",
    "AXIS_TEXT_SIZE=12\n",
    "LEGEND_TEXT_SIZE=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_policy(env, agent, cfg, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Handy variables\n",
    "    maze_countours = maze.env.maze.matrix\n",
    "    max_x = env.env.maze.max_x\n",
    "    max_y = env.env.maze.max_y\n",
    "\n",
    "    fitness_matrix = build_fitness_matrix(env, agent.population, cfg)\n",
    "    action_matrix = build_action_matrix(env, agent.population, cfg)\n",
    "\n",
    "    # Render maze as image\n",
    "    plt.imshow(fitness_matrix, interpolation='nearest', cmap='Reds', aspect='auto',\n",
    "           extent=[0, max_x, max_y, 0])\n",
    "\n",
    "\n",
    "    # Add labels to each cell\n",
    "    for (y,x), val in np.ndenumerate(action_matrix):\n",
    "        plt.text(x+0.4, y+0.5, \"${}$\".format(val))\n",
    "\n",
    "    ax.set_title(\"Policy\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel('x', fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel('y', fontsize=AXIS_TEXT_SIZE)\n",
    "\n",
    "    ax.set_xlim(0, max_x)\n",
    "    ax.set_ylim(1+max_y, 0)\n",
    "\n",
    "    ax.set_xticks(range(0, max_x+1))\n",
    "    ax.set_yticks(range(0, max_y+1))\n",
    "\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_knowledge(df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    explore_df = df.query(\"phase == 'explore'\")\n",
    "    exploit_df = df.query(\"phase == 'exploit'\")\n",
    "\n",
    "    explore_df['knowledge'].plot(ax=ax, c='blue')\n",
    "    exploit_df['knowledge'].plot(ax=ax, c='red')\n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "\n",
    "    ax.set_title(\"Achieved knowledge\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel(\"Trial\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel(\"Knowledge [%]\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylim([0, 105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_steps(df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    explore_df = df.query(\"phase == 'explore'\")\n",
    "    exploit_df = df.query(\"phase == 'exploit'\")\n",
    "\n",
    "    explore_df['steps'].plot(ax=ax, c='blue', linewidth=.5)\n",
    "    exploit_df['steps'].plot(ax=ax, c='red', linewidth=0.5)\n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "\n",
    "    ax.set_title(\"Steps\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel(\"Trial\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel(\"Steps\", fontsize=AXIS_TEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_classifiers(df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    explore_df = df.query(\"phase == 'explore'\")\n",
    "    exploit_df = df.query(\"phase == 'exploit'\")\n",
    "\n",
    "    df['numerosity'].plot(ax=ax, c='blue')\n",
    "    df['reliable'].plot(ax=ax, c='red')\n",
    "\n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "\n",
    "    ax.set_title(\"Classifiers\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel(\"Trial\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel(\"Classifiers\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_TEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_performance(agent, maze, metrics_df, cfg, env_name):\n",
    "    plt.figure(figsize=(13, 10), dpi=100)\n",
    "    plt.suptitle(f'ACS2 Performance in {env_name} environment', fontsize=32)\n",
    "\n",
    "    ax1 = plt.subplot(221)\n",
    "    plot_policy(maze, agent, cfg, ax1)\n",
    "\n",
    "    ax2 = plt.subplot(222)\n",
    "    plot_knowledge(metrics_df, ax2)\n",
    "\n",
    "    ax3 = plt.subplot(223)\n",
    "    plot_classifiers(metrics_df, ax3)\n",
    "\n",
    "    ax4 = plt.subplot(224)\n",
    "    plot_steps(metrics_df, ax4)\n",
    "\n",
    "    plt.subplots_adjust(top=0.86, wspace=0.3, hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestMaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define agent's default configuration\n",
    "cfg = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_ga=True,\n",
    "    do_subsumption=True,\n",
    "    do_action_planning=False,\n",
    "    action_planning_frequency=50,\n",
    "    beta=0.05,\n",
    "    gamma=0.95,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.5,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8\n",
    ")\n",
    "\n",
    "# Get the accurate environment\n",
    "# define environment\n",
    "testMaze = gym.make('Woods14-v0')\n",
    "\n",
    "# explore\n",
    "agent_testMaze = ACS2(cfg)\n",
    "population_testMaze_explore, metrics_testMaze_explore = agent_testMaze.explore(testMaze, 3000)\n",
    "\n",
    "# exploit\n",
    "agent_testMaze = ACS2(cfg, population_testMaze_explore)\n",
    "_, metrics_testMaze_exploit = agent_testMaze.exploit(testMaze, 400)\n",
    "\n",
    "# plot performance\n",
    "testMaze_metrics_df = parse_metrics_to_df(metrics_testMaze_explore, metrics_testMaze_exploit)\n",
    "plot_performance(agent_testMaze, testMaze, testMaze_metrics_df, cfg, 'Woods14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_step = 0\n",
    "for trial in metrics_testMaze_exploit:\n",
    "    avg_step += trial['steps_in_trial']\n",
    "avg_step /= 400\n",
    "print(\"Average number of steps to solve the maze is \",avg_step, \" for a total of \", 400, \" trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Mazes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define agent's default configuration\n",
    "cfg = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_ga=False,\n",
    "    do_subsumption=True,\n",
    "    do_action_planning=False,\n",
    "    action_planning_frequency=50,\n",
    "    beta=0.05,\n",
    "    gamma=0.95,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.5,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8\n",
    ")\n",
    "\n",
    "# Get the accurate environment\n",
    "filter_envs = lambda env: env.id.startswith(\"Maze\")\n",
    "all_envs = [env for env in gym.envs.registry.all()]\n",
    "maze_envs = [env for env in all_envs if filter_envs(env)]\n",
    "\n",
    "for env in maze_envs:\n",
    "    # define environement\n",
    "    maze = gym.make(env.id)\n",
    "    # explore\n",
    "    agent_maze = ACS2(cfg)\n",
    "    population_maze_explore, metrics_maze_explore = agent_maze.explore(maze, 3000)\n",
    "    # exploit\n",
    "    agent_maze = ACS2(cfg, population_maze_explore)\n",
    "    _, metrics_maze_exploit = agent_maze.exploit(maze, 400)\n",
    "    # plot performance\n",
    "    maze_metrics_df = parse_metrics_to_df(metrics_maze_explore, metrics_maze_exploit)\n",
    "    plot_performance(agent_maze, maze, maze_metrics_df, cfg, env.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Woods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define agent's default configuration\n",
    "cfg = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_ga=False,\n",
    "    do_subsumption=True,\n",
    "    do_action_planning=False,\n",
    "    action_planning_frequency=50,\n",
    "    beta=0.05,\n",
    "    gamma=0.95,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.5,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8\n",
    ")\n",
    "\n",
    "# Get the accurate environment\n",
    "filter_envs = lambda env: env.id.startswith(\"Woods\")\n",
    "all_envs = [env for env in gym.envs.registry.all()]\n",
    "maze_envs = [env for env in all_envs if filter_envs(env)]\n",
    "\n",
    "for env in maze_envs:\n",
    "    # define environement\n",
    "    maze = gym.make(env.id)\n",
    "    # explore\n",
    "    agent_maze = ACS2(cfg)\n",
    "    population_maze_explore, metrics_maze_explore = agent_maze.explore(maze, 3000)\n",
    "    # exploit\n",
    "    agent_maze = ACS2(cfg, population_maze_explore)\n",
    "    _, metrics_maze_exploit = agent_maze.exploit(maze, 400)\n",
    "    # plot performance\n",
    "    maze_metrics_df = parse_metrics_to_df(metrics_maze_explore, metrics_maze_exploit)\n",
    "    plot_performance(agent_maze, maze, maze_metrics_df, cfg, env.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Littman and Miyazaki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define agent's default configuration\n",
    "cfg = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    user_metrics_collector_fcn=_maze_metrics,\n",
    "    metrics_trial_frequency=1,\n",
    "    do_ga=False,\n",
    "    do_subsumption=True,\n",
    "    do_action_planning=False,\n",
    "    action_planning_frequency=50,\n",
    "    beta=0.05,\n",
    "    gamma=0.95,\n",
    "    theta_i=0.1,\n",
    "    theta_r=0.9,\n",
    "    epsilon=0.5,\n",
    "    u_max=CLASSIFIER_LENGTH,\n",
    "    theta_exp=20,\n",
    "    theta_ga=100,\n",
    "    theta_as=20,\n",
    "    mu=0.3,\n",
    "    chi=0.8\n",
    ")\n",
    "\n",
    "# Get the accurate environment\n",
    "filter_envs = lambda env: env.id.startswith(\"Littman\") or env.id.startswith(\"Miyazaki\")\n",
    "all_envs = [env for env in gym.envs.registry.all()]\n",
    "maze_envs = [env for env in all_envs if filter_envs(env)]\n",
    "\n",
    "for env in maze_envs:\n",
    "    # define environement\n",
    "    maze = gym.make(env.id)\n",
    "    # explore\n",
    "    agent_maze = ACS2(cfg)\n",
    "    population_maze_explore, metrics_maze_explore = agent_maze.explore(maze, 3000)\n",
    "    # exploit\n",
    "    agent_maze = ACS2(cfg, population_maze_explore)\n",
    "    _, metrics_maze_exploit = agent_maze.exploit(maze, 400)\n",
    "    # plot performance\n",
    "    maze_metrics_df = parse_metrics_to_df(metrics_maze_explore, metrics_maze_exploit)\n",
    "    plot_performance(agent_maze, maze, maze_metrics_df, cfg, env.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
