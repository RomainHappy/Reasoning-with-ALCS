{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    file, You can obtain one at http://mozilla.org/MPL/2.0/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statsmodels.stats import weightstats as stests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameter to build seaborn boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/IWLCS/'\n",
    "offset_path = len(path)\n",
    "\n",
    "# Comment or uncomment following paths to see results for each experience we conduct\n",
    "\n",
    "# A ) ACS2 without PEPs vs ACS2 with PEPs. Both without GA and with Biased Exploration\n",
    "#file_name_lcs_1 = 'acs2_no_pees.json'\n",
    "#file_name_lcs_2 = 'acs2_pees.json'\n",
    "\n",
    "# B ) ACS2 without GA vs ACS2 with GA. Both with Biased Exploration and PEPs\n",
    "#file_name_lcs_1 = 'acs2_pees.json'\n",
    "#file_name_lcs_2 = 'acs2_pees_ga.json'\n",
    "\n",
    "# C ) ACS2 without Biased Epxloration vs ACS2 with Biased Exploration. Both with GA and with PEPs\n",
    "#file_name_lcs_1 = 'acs2_pees_ga_no_be.json'\n",
    "#file_name_lcs_2 = 'acs2_pees_ga.json'\n",
    "\n",
    "# D ) ACS2 without Biased Exploration vs ACS2 with Biased Exploration. Both without GA and with PEPs\n",
    "#file_name_lcs_1 = 'acs2_pees_no_be.json'\n",
    "#file_name_lcs_2 = 'acs2_pees.json'\n",
    "\n",
    "# E ) ACS2 without constraints on creaPEPs vs ACS2 with constraints on creaPEPs. \n",
    "#     Both with PEPs and with Biased Exploration and without GA\n",
    "#file_name_lcs_1 = 'acs2_pees_no_constraints.json'\n",
    "#file_name_lcs_2 = 'acs2_pees.json'\n",
    "\n",
    "# F ) ACS2 without constraints on creaPEPs vs ACS2 with constraints on creaPEPs. \n",
    "#     Both with PEPs and with Biased Exploration and with GA\n",
    "#file_name_lcs_1 = 'acs2_pees_ga_no_constraints.json'\n",
    "#file_name_lcs_2 = 'acs2_pees_ga.json'\n",
    "\n",
    "json_data_from_lcs_1 = path + file_name_lcs_1\n",
    "json_data_from_lcs_2 = path + file_name_lcs_2\n",
    "\n",
    "# Font size et figuresize parameters for plotting\n",
    "\n",
    "figure_size = (20, 10)\n",
    "axe_label_fontsize = '24'\n",
    "tick_label_fontsize = '20'\n",
    "legend_fontsize = '20'\n",
    "\n",
    "# Significiance level\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_data_from_lcs_1) as json_file_1:\n",
    "    raw_data_from_lcs_1 = json.load(json_file_1)\n",
    "    \n",
    "with open(json_data_from_lcs_2) as json_file_2:\n",
    "    raw_data_from_lcs_2 = json.load(json_file_2)\n",
    "\n",
    "raw_data = [raw_data_from_lcs_1,raw_data_from_lcs_2]\n",
    "lcs_name = [json_data_from_lcs_1[offset_path:-5], json_data_from_lcs_2[offset_path:-5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing pandas plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = {\n",
    "    'LCS':[], \n",
    "    'Maze':[], \n",
    "    'Knowledge (%)':[],\n",
    "    'Population of macro classifiers':[], \n",
    "    'Reliable classifiers':[],\n",
    "    'Ratio of enhanced classifiers matching non aliased states':[], \n",
    "    'Mean realiable classifier specificity':[], \n",
    "    'Full Knowledge for first time (trial)':[], \n",
    "    'Stable Full Knowledge (trial)':[]\n",
    "}\n",
    "\n",
    "nb_of_environments = 0\n",
    "\n",
    "for i in range(len(lcs_name)):\n",
    "    for item in raw_data[i]:\n",
    "        if 'time' not in item.keys():\n",
    "            nb_of_environments += 1\n",
    "            for idx in range(len(item['knowledge_list'])):\n",
    "                cleaned_data['LCS'].append(lcs_name[i])\n",
    "                cleaned_data['Maze'].append(item['maze'])\n",
    "                cleaned_data['Knowledge (%)'].append(item['knowledge_list'][idx])\n",
    "                cleaned_data['Population of macro classifiers'].append(item['population_list'][idx])\n",
    "                cleaned_data['Reliable classifiers'].append(item['reliable_list'][idx])\n",
    "                cleaned_data['Ratio of enhanced classifiers matching non aliased states'].append(\n",
    "                    float(item['pees_matching_non_aliased_states_list'][idx]) / item['population_list'][idx]\n",
    "                )\n",
    "                cleaned_data['Mean realiable classifier specificity'].append(item['mean_reliable_classifier_specificity_list'][idx])\n",
    "                if item['full_knowledge_first_trial_list'][idx] == -1:\n",
    "                    cleaned_data['Full Knowledge for first time (trial)'].append(\n",
    "                        5000\n",
    "                    )\n",
    "                else:\n",
    "                    cleaned_data['Full Knowledge for first time (trial)'].append(\n",
    "                        item['full_knowledge_first_trial_list'][idx]\n",
    "                    )\n",
    "                if item['full_knowledge_stable_trial_list'][idx] == -1:\n",
    "                    cleaned_data['Stable Full Knowledge (trial)'].append(\n",
    "                        5000\n",
    "                    )\n",
    "                else:\n",
    "                    cleaned_data['Stable Full Knowledge (trial)'].append(\n",
    "                        item['full_knowledge_stable_trial_list'][idx]\n",
    "                    )\n",
    "\n",
    "nb_of_environments /= len(lcs_name)\n",
    "                \n",
    "pandas_data = pd.DataFrame(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing statistical data from raw read json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_by_env_name = {}\n",
    "for i in range(len(lcs_name)):\n",
    "    for item in raw_data[i]:\n",
    "        if 'time' not in item.keys():\n",
    "            if item['maze'] not in raw_list_by_env_name.keys():\n",
    "                raw_list_by_env_name[item['maze']] = {\n",
    "                    'knowledge_list' : [],\n",
    "                    'population_list' : [],\n",
    "                    'reliable_list' : [],\n",
    "                    'pees_matching_non_aliased_states_list' : [],\n",
    "                    'mean_reliable_classifier_specificity_list' : [],\n",
    "                    'full_knowledge_first_trial_list' : [],\n",
    "                    'full_knowledge_stable_trial_list' : []\n",
    "                }\n",
    "            raw_list_by_env_name[item['maze']]['knowledge_list'].append(\n",
    "                np.array(item['knowledge_list']))\n",
    "            raw_list_by_env_name[item['maze']]['population_list'].append(np.array(\n",
    "                item['population_list']))\n",
    "            raw_list_by_env_name[item['maze']]['reliable_list'].append(np.array(\n",
    "                item['reliable_list']))\n",
    "            raw_list_by_env_name[item['maze']]['pees_matching_non_aliased_states_list'].append(np.array(\n",
    "                [float(a)/b for a,b in zip(item['pees_matching_non_aliased_states_list'], item['population_list'])]))\n",
    "            raw_list_by_env_name[item['maze']]['mean_reliable_classifier_specificity_list'].append(\n",
    "                np.array(item['mean_reliable_classifier_specificity_list']))\n",
    "            raw_list_by_env_name[item['maze']]['full_knowledge_first_trial_list'].append(\n",
    "                np.array(item['full_knowledge_first_trial_list']))\n",
    "            raw_list_by_env_name[item['maze']]['full_knowledge_stable_trial_list'].append(\n",
    "                np.array(item['full_knowledge_stable_trial_list']))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting boxplots with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc={\n",
    "    'axes.labelsize':axe_label_fontsize,\n",
    "    'xtick.labelsize':tick_label_fontsize,\n",
    "    'ytick.labelsize':tick_label_fontsize\n",
    "}\n",
    "sns.set(context='notebook', style='ticks', rc=rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(pandas_data, Y, legend_loc):\n",
    "    \n",
    "    # Build the main figure\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    sns.stripplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        edgecolor='gray',\n",
    "        jitter=True,\n",
    "        linewidth = 1,\n",
    "        dodge=True,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        fliersize=0,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )\n",
    "\n",
    "    # Set up x tick labels and x label correctly\n",
    "    plt.xticks(rotation = 45, horizontalalignment = 'right')\n",
    "    plt.xlabel('')\n",
    "\n",
    "    # Hide the horizontal gridlines\n",
    "    ax.yaxis.grid(False)\n",
    "\n",
    "    # Show the vertical gridlines\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    # Shift major ticks to create column for each maze\n",
    "    plt.xticks(np.arange(nb_of_environments)+0.5)\n",
    "\n",
    "    # Set up minor ticks and align label of major ticks on minor ticks\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(0.5))\n",
    "    dx = (((figure_size[0] * 100 / 4.))/nb_of_environments - 10)/72.; dy = 0/72. # Width in inches converted into pixels depending on default DPI\n",
    "    offset = matplotlib.transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "    for label in ax.xaxis.get_majorticklabels():\n",
    "        label.set_transform(label.get_transform() - offset)\n",
    "\n",
    "    # Set up legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[0:2], labels[0:2], frameon=False, loc=legend_loc, fontsize=legend_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knowledge(pandas_data, zipped:bool=True):\n",
    "        \n",
    "    plot_figure(pandas_data, Y='Knowledge (%)', legend_loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_population(pandas_data, only_reliable:bool=False):\n",
    "\n",
    "    if not only_reliable:\n",
    "        Y = 'Population of macro classifiers'\n",
    "    else:\n",
    "        Y = 'Reliable classifiers'\n",
    "\n",
    "    plot_figure(pandas_data, Y=Y, legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_non_aliased_pees_ratio(pandas_data):\n",
    "    \n",
    "    plot_figure(pandas_data, Y='Ratio of enhanced classifiers matching non aliased states', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_classifier_specificity(pandas_data):\n",
    "    \n",
    "    plot_figure(pandas_data, Y='Mean realiable classifier specificity', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_time_full_knowledge_achieved(pandas_data):\n",
    "    \n",
    "    plot_figure(pandas_data, Y='Full Knowledge for first time (trial)', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stable_full_knowledge_achieved(pandas_data):\n",
    "    \n",
    "    plot_figure(pandas_data, Y='Stable Full Knowledge (trial)', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_knowledge(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population(pandas_data, only_reliable=False)\n",
    "plot_population(pandas_data, only_reliable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_non_aliased_pees_ratio(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_classifier_specificity(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_first_time_full_knowledge_achieved(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stable_full_knowledge_achieved(pandas_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_statistical_data = {\n",
    "    'Maze':[],\n",
    "    'Metric':[],\n",
    "    'Alternative':[],\n",
    "    'P Value':[],\n",
    "    'Null Hypothesis':[]\n",
    "}\n",
    "for env_name in raw_list_by_env_name.keys():\n",
    "    for metric in raw_list_by_env_name[env_name].keys():\n",
    "        for i in range(3):\n",
    "            raw_statistical_data['Maze'].append(env_name)\n",
    "            raw_statistical_data['Metric'].append(metric)\n",
    "            array1 = stests.DescrStatsW(raw_list_by_env_name[env_name][metric][0])\n",
    "            array2 = stests.DescrStatsW(raw_list_by_env_name[env_name][metric][1])\n",
    "            if i == 0:\n",
    "                raw_statistical_data['Alternative'].append('two-sided')\n",
    "                tstats, pvalue = stests.CompareMeans(array1,array2).ztest_ind(\n",
    "                    alternative='two-sided', usevar='unequal', value=0)\n",
    "            elif i == 1:\n",
    "                raw_statistical_data['Alternative'].append('larger')\n",
    "                tstats, pvalue = stests.CompareMeans(array1,array2).ztest_ind(\n",
    "                    alternative='larger', usevar='unequal', value=0)\n",
    "            else:\n",
    "                raw_statistical_data['Alternative'].append('smaller')\n",
    "                tstats, pvalue = stests.CompareMeans(array1,array2).ztest_ind(\n",
    "                    alternative='smaller', usevar='unequal', value=0)\n",
    "            raw_statistical_data['P Value'].append(pvalue)\n",
    "            if pvalue<alpha:\n",
    "                raw_statistical_data['Null Hypothesis'].append('Reject')\n",
    "            else:\n",
    "                raw_statistical_data['Null Hypothesis'].append('Accept')\n",
    "statistical_pandas = pd.DataFrame(raw_statistical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_pandas.to_csv(path + lcs_name[0] + '_' + lcs_name[1] + '_stats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
