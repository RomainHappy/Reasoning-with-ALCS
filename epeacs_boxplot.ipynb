{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    file, You can obtain one at http://mozilla.org/MPL/2.0/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be sure that all modules listed below are installed on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statsmodels.stats import weightstats as stests\n",
    "#Violinplot Ã  tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameter to build seaborn boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, update the path where all data are located.\n",
    "# All computed p-values are gathered in a CSV file saved in the folder 'path'\n",
    "# whose file name depends on the experiment results you want to see\n",
    "path = 'data/TPNC/'\n",
    "offset_path = len(path)\n",
    "\n",
    "# Comment or uncomment the following lines to see results (figures and p-values) for each conducted experiment\n",
    "# Source code will be available on github soon...\n",
    "\n",
    "# 0 ) PEPACS vs EPEACS vs ACS2\n",
    "#     On all mazes without slippery and random attributes\n",
    "#file_name_lcs_1 = 'acs2.json'\n",
    "#file_name_lcs_1 = 'pepacs.json'\n",
    "\n",
    "# A ) PEPACS vs EPEACS\n",
    "#     On all mazes with random attribute with fifty per cent chance to get each random attribute\n",
    "#file_name_lcs_1 = 'acs2_ra_50_50.json'\n",
    "#file_name_lcs_2 = 'pepacs_ra_50_50.json'\n",
    "\n",
    "# B ) PEPACS vs EPEACS\n",
    "#     On all mazes with random attribute with 90_10 per cent chance to get each random attribute\n",
    "#file_name_lcs_1 = 'acs2_ra_90_10.json'\n",
    "#file_name_lcs_2 = 'pepacs_ra_90_10.json'\n",
    "\n",
    "# C ) PEPACS vs EPEACS\n",
    "#     On all mazes with slippery\n",
    "#file_name_lcs_1 = 'acs2_slippery.json'\n",
    "#file_name_lcs_2 = 'pepacs_slippery.json'\n",
    "\n",
    "# D ) PEPACS vs EPEACS\n",
    "#     On all mazes with slippery and random attribute\n",
    "#file_name_lcs_1 = 'acs2_slippery_ra.json'\n",
    "#file_name_lcs_2 = 'pepacs_slippery_ra.json'\n",
    "\n",
    "\n",
    "# E ) BACS vs BACASABLE\n",
    "#     On all mazes without slippery, ra, ga and with bseq =1 and pep\n",
    "#file_name_lcs_1 = '../bacs-bseq2-1000-0.8-ga-anticipatechange.json'\n",
    "#file_name_lcs_1 = '../bacs-bseq2-1000-0.8-ga-gaonbseq-anticipatechange.json'\n",
    "#file_name_lcs_1 = '../bacs-bseq2-1000-0.8.json'\n",
    "#file_name_lcs_1 = '../bacs-bseq2-1000-0.8-ga.json'\n",
    "#file_name_lcs_1 = '../bacs-bseq2-5000-0.8.json'\n",
    "#file_name_lcs_1 = '../bacs-bseq2-5000-0.8-ga.json'\n",
    "#file_name_lcs_2 = '../epeacs-bseq2-5000-0.8.json'\n",
    "#file_name_lcs_2 = '../epeacs-bseq2-5000-0.8-ga.json'\n",
    "#file_name_lcs_2 = '../epeacs-bseq2-5000-0.8-slippery-0.25.json'\n",
    "#file_name_lcs_2 = '../epeacs-bseq2-5000-0.8-ga-slippery-0.25.json'\n",
    "\n",
    "\n",
    "# Font size et figuresize parameters for plotting\n",
    "figure_size = (20, 10)\n",
    "axe_label_fontsize = '28'\n",
    "tick_label_fontsize = '24'\n",
    "legend_fontsize = '24'\n",
    "\n",
    "# Significance level for p-values\n",
    "alpha = 0.05\n",
    "produce_stat = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please, do not modify any lines of code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path, file_name_lcs_1, file_name_lcs_2):\n",
    "    json_data_from_lcs_1 = path + file_name_lcs_1\n",
    "    json_data_from_lcs_2 = path + file_name_lcs_2\n",
    "\n",
    "    with open(json_data_from_lcs_1) as json_file_1:\n",
    "        raw_data_from_lcs_1 = json.load(json_file_1)\n",
    "\n",
    "    with open(json_data_from_lcs_2) as json_file_2:\n",
    "        raw_data_from_lcs_2 = json.load(json_file_2)\n",
    "\n",
    "    raw_data = [raw_data_from_lcs_1, raw_data_from_lcs_2, raw_data_from_lcs_2]\n",
    "    lcs_name = [file_name_lcs_1, file_name_lcs_2]\n",
    "    #lcs_name = ['ACS2', 'PEPACS', 'EPEACS']\n",
    "    return raw_data, lcs_name\n",
    "\n",
    "# Call function to prepare plotting data\n",
    "raw_data, lcs_name = read_json(path, file_name_lcs_1, file_name_lcs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing pandas plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pandas_plotting_data(raw_data, lcs_name):\n",
    "    cleaned_data = {\n",
    "        'LCS':[], \n",
    "        'Maze':[], \n",
    "        'Knowledge (%)':[],\n",
    "        'Population of classifiers':[], \n",
    "        'Reliable classifiers':[], \n",
    "        'Mean realiable classifier specificity':[], \n",
    "        #'Full Knowledge for first time (trial)':[],\n",
    "        #'Full Knowledge stable (trial)':[],\n",
    "        #'Full Knowledge for last time (trial)':[],\n",
    "        'PEP Accumulated Error (%)':[],\n",
    "        'Average steps to exit':[]\n",
    "    }\n",
    "    nb_of_environments = 0\n",
    "    for i in range(len(lcs_name)):\n",
    "        for item in raw_data[i]:\n",
    "            if 'time' not in item.keys():\n",
    "                nb_of_environments += 1\n",
    "                for idx in range(len(item['knowledge_list'])):\n",
    "                    cleaned_data['LCS'].append(lcs_name[i])\n",
    "                    if item['maze'][:-3] == \"Woods101demi\":\n",
    "                        cleaned_data['Maze'].append(\"Woods101.5\")\n",
    "                    else:\n",
    "                        cleaned_data['Maze'].append(item['maze'][:-3])\n",
    "                    cleaned_data['Knowledge (%)'].append(item['knowledge_list'][idx])\n",
    "                    cleaned_data['Population of classifiers'].append(item['population_list'][idx])\n",
    "                    cleaned_data['Reliable classifiers'].append(item['reliable_list'][idx])\n",
    "                    cleaned_data['Mean realiable classifier specificity'].append(\n",
    "                        item['mean_reliable_classifier_specificity_list'][idx]\n",
    "                    )\n",
    "                    #cleaned_data['Full Knowledge for first time (trial)'].append(\n",
    "                    #    item['full_knowledge_first_trial_list'][idx]\n",
    "                    #)\n",
    "                    #cleaned_data['Full Knowledge stable (trial)'].append(\n",
    "                    #    item['full_knowledge_stable_trial_list'][idx]\n",
    "                    #)\n",
    "                    #cleaned_data['Full Knowledge for last time (trial)'].append(\n",
    "                    #    item['full_knowledge_last_trial_list'][idx]\n",
    "                    #)\n",
    "                    if i == 1:\n",
    "                        cleaned_data['PEP Accumulated Error (%)'].append(item['old_pep_error_list'][idx])\n",
    "                    else:\n",
    "                        cleaned_data['PEP Accumulated Error (%)'].append(item['new_pep_error_list'][idx])\n",
    "                    cleaned_data['Average steps to exit'].append(\n",
    "                        item['avg_exploit_rl_list'][idx]\n",
    "                    )\n",
    "\n",
    "    nb_of_environments /= len(lcs_name)\n",
    "    pandas_data = pd.DataFrame(cleaned_data)\n",
    "    return nb_of_environments, pandas_data\n",
    "\n",
    "nb_of_environments, pandas_data = prepare_pandas_plotting_data(raw_data, lcs_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting boxplots with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc={\n",
    "    'axes.labelsize':axe_label_fontsize,\n",
    "    'xtick.labelsize':tick_label_fontsize,\n",
    "    'ytick.labelsize':tick_label_fontsize\n",
    "}\n",
    "sns.set(context='notebook', style='ticks', rc=rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(pandas_data, Y, legend_loc, lcs_name):\n",
    "    \n",
    "    # Build the main figure\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    sns.stripplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        edgecolor='gray',\n",
    "        jitter=True,\n",
    "        linewidth = 1,\n",
    "        dodge=True,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )#violinplot\n",
    "    sns.boxplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        fliersize=0,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )\n",
    "\n",
    "    # Set up x tick labels and x label correctly\n",
    "    plt.xticks(rotation = 45, horizontalalignment = 'right')\n",
    "    plt.xlabel('')\n",
    "\n",
    "    # Hide the horizontal gridlines\n",
    "    ax.yaxis.grid(False)\n",
    "\n",
    "    # Show the vertical gridlines\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    # Shift major ticks to create column for each maze\n",
    "    plt.xticks(np.arange(nb_of_environments)+0.5)\n",
    "\n",
    "    # Set up minor ticks and align label of major ticks on minor ticks\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(0.5))\n",
    "    dx = (((figure_size[0] * 100 / 4.))/nb_of_environments - 10)/72.; dy = 0/72. # Width in inches converted into pixels depending on default DPI\n",
    "    offset = matplotlib.transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "    for label in ax.xaxis.get_majorticklabels():\n",
    "        label.set_transform(label.get_transform() - offset)\n",
    "\n",
    "    # Set up legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if len(lcs_name) == 2:\n",
    "        plt.legend(handles[0:2], labels[0:2], frameon=False, loc=legend_loc, fontsize=legend_fontsize)\n",
    "    else:\n",
    "        plt.legend(handles[0:3], labels[0:3], frameon=False, loc=legend_loc, fontsize=legend_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knowledge(pandas_data, zipped:bool=True):\n",
    "    plot_figure(pandas_data, Y='Knowledge (%)', legend_loc='lower right', lcs_name=lcs_name)\n",
    "    \n",
    "def plot_population(pandas_data, only_reliable:bool=False):\n",
    "    if not only_reliable:\n",
    "        Y = 'Population of classifiers'\n",
    "    else:\n",
    "        Y = 'Reliable classifiers'\n",
    "    plot_figure(pandas_data, Y=Y, legend_loc='upper right', lcs_name=lcs_name)\n",
    "\n",
    "def plot_mean_classifier_specificity(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Mean realiable classifier specificity', legend_loc='upper right', lcs_name=lcs_name)\n",
    "\n",
    "#def plot_first_time_full_knowledge_achieved(pandas_data):\n",
    "#    plot_figure(pandas_data, Y='Full Knowledge for first time (trial)', legend_loc='upper right', lcs_name=lcs_name)\n",
    "\n",
    "#def plot_last_time_full_knowledge_achieved(pandas_data):\n",
    "#    plot_figure(pandas_data, Y='Full Knowledge for last time (trial)', legend_loc='lower right', lcs_name=lcs_name)\n",
    "\n",
    "def plot_pep_accumulated_error(pandas_data):\n",
    "    plot_figure(pandas_data, Y='PEP Accumulated Error (%)', legend_loc='upper right', lcs_name=lcs_name)\n",
    "\n",
    "def plot_avg_steps_to_exit(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Average steps to exit', legend_loc='upper right', lcs_name=lcs_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_knowledge(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population(pandas_data, only_reliable=False)\n",
    "plot_population(pandas_data, only_reliable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_classifier_specificity(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pep_accumulated_error(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_steps_to_exit(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_first_time_full_knowledge_achieved(pandas_data)\n",
    "#plot_last_time_full_knowledge_achieved(pandas_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing statistical data from raw read json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_stat:\n",
    "    raw_list_by_env_name = {}\n",
    "    for i in range(len(lcs_name)):\n",
    "        for item in raw_data[i]:\n",
    "            if 'time' not in item.keys():\n",
    "                if item['maze'] not in raw_list_by_env_name.keys():\n",
    "                    raw_list_by_env_name[item['maze']] = {\n",
    "                        'knowledge_list' : [],\n",
    "                        'population_list' : [],\n",
    "                        'reliable_list' : [],\n",
    "                        'mean_reliable_classifier_specificity_list' : [],\n",
    "                        'full_knowledge_first_trial_list' : [],\n",
    "                        'full_knowledge_last_trial_list' : [],\n",
    "                        'PEP_Accumulated_Error' : []\n",
    "                    }\n",
    "                raw_list_by_env_name[item['maze']]['knowledge_list'].append(\n",
    "                    np.array(item['knowledge_list']))\n",
    "                raw_list_by_env_name[item['maze']]['population_list'].append(\n",
    "                    np.array(item['population_list']))\n",
    "                raw_list_by_env_name[item['maze']]['reliable_list'].append(\n",
    "                    np.array(item['reliable_list']))\n",
    "                raw_list_by_env_name[item['maze']]['mean_reliable_classifier_specificity_list'].append(\n",
    "                    np.array(item['mean_reliable_classifier_specificity_list']))\n",
    "                raw_list_by_env_name[item['maze']]['full_knowledge_first_trial_list'].append(\n",
    "                    np.array(item['full_knowledge_first_trial_list']))\n",
    "                raw_list_by_env_name[item['maze']]['full_knowledge_last_trial_list'].append(\n",
    "                    np.array(item['full_knowledge_last_trial_list']))\n",
    "                if i == 1:\n",
    "                    raw_list_by_env_name[item['maze']]['PEP_Accumulated_Error'].append(\n",
    "                        np.array(item['old_pep_error_list']))\n",
    "                else:\n",
    "                    raw_list_by_env_name[item['maze']]['PEP_Accumulated_Error'].append(\n",
    "                        np.array(item['new_pep_error_list']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_stat:\n",
    "    raw_statistical_data = {\n",
    "        'Maze':[],\n",
    "        'Metric':[],\n",
    "        'ALCS':[],\n",
    "        'Alternative':[],\n",
    "        'Degrees of freedom':[],\n",
    "        'P Value':[],\n",
    "        'Null Hypothesis':[]\n",
    "    }\n",
    "    for env_name in raw_list_by_env_name.keys():\n",
    "        for metric in raw_list_by_env_name[env_name].keys():\n",
    "            for i in range(3):\n",
    "                raw_statistical_data['Maze'].append(env_name)\n",
    "                raw_statistical_data['Metric'].append(metric)\n",
    "                raw_statistical_data['ALCS'].append('ACS2-PEPACS')\n",
    "                x1 = np.array(raw_list_by_env_name[env_name][metric][0])\n",
    "                x2 = np.array(raw_list_by_env_name[env_name][metric][1])\n",
    "                if i == 0:\n",
    "                    alt = 'two-sided'\n",
    "                elif i == 1:\n",
    "                    alt = 'larger'\n",
    "                else:\n",
    "                    alt = 'smaller'\n",
    "                raw_statistical_data['Alternative'].append(alt)\n",
    "                tstats, pvalue, dof = stests.ttest_ind(x1, x2, alternative=alt, usevar='unequal', value=0)\n",
    "                raw_statistical_data['Degrees of freedom'].append(dof)\n",
    "                raw_statistical_data['P Value'].append(pvalue)\n",
    "                if pvalue<alpha:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Reject')\n",
    "                else:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Accept')\n",
    "\n",
    "                raw_statistical_data['Maze'].append(env_name)\n",
    "                raw_statistical_data['Metric'].append(metric)\n",
    "                raw_statistical_data['ALCS'].append('ACS2-EPEACS')\n",
    "                x1 = np.array(raw_list_by_env_name[env_name][metric][0])\n",
    "                x2 = np.array(raw_list_by_env_name[env_name][metric][2])\n",
    "                if i == 0:\n",
    "                    alt = 'two-sided'\n",
    "                elif i == 1:\n",
    "                    alt = 'larger'\n",
    "                else:\n",
    "                    alt = 'smaller'\n",
    "                raw_statistical_data['Alternative'].append(alt)\n",
    "                tstats, pvalue, dof = stests.ttest_ind(x1, x2, alternative=alt, usevar='unequal', value=0)\n",
    "                raw_statistical_data['Degrees of freedom'].append(dof)\n",
    "                raw_statistical_data['P Value'].append(pvalue)\n",
    "                if pvalue<alpha:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Reject')\n",
    "                else:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Accept')\n",
    "\n",
    "                raw_statistical_data['Maze'].append(env_name)\n",
    "                raw_statistical_data['Metric'].append(metric)\n",
    "                raw_statistical_data['ALCS'].append('PEPACS-EPEACS')\n",
    "                x1 = np.array(raw_list_by_env_name[env_name][metric][1])\n",
    "                x2 = np.array(raw_list_by_env_name[env_name][metric][2])\n",
    "                if i == 0:\n",
    "                    alt = 'two-sided'\n",
    "                elif i == 1:\n",
    "                    alt = 'larger'\n",
    "                else:\n",
    "                    alt = 'smaller'\n",
    "                raw_statistical_data['Alternative'].append(alt)\n",
    "                tstats, pvalue, dof = stests.ttest_ind(x1, x2, alternative=alt, usevar='unequal', value=0)\n",
    "                raw_statistical_data['Degrees of freedom'].append(dof)\n",
    "                raw_statistical_data['P Value'].append(pvalue)\n",
    "                if pvalue<alpha:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Reject')\n",
    "                else:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Accept')\n",
    "    statistical_pandas = pd.DataFrame(raw_statistical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_stat:\n",
    "    statistical_pandas.to_csv(path + file_name_lcs_1 + '_&_' + file_name_lcs_2 + '_stats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
