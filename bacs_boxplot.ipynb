{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    file, You can obtain one at http://mozilla.org/MPL/2.0/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be sure that all modules listed below are installed on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statsmodels.stats import weightstats as stests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameter to build seaborn boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, update the path where all data are located.\n",
    "# All computed p-values are gathered in a CSV file saved in the folder 'path'\n",
    "# whose file name depends on the experiment results you want to see\n",
    "path = 'data/PPSN/'\n",
    "offset_path = len(path)\n",
    "\n",
    "# Comment or uncomment the following lines to see results (figures and p-values) for each conducted experiment\n",
    "# Source code will be available on github soon...\n",
    "\n",
    "# A1 ) ACS2 and BACS-1 in non aliased environments\n",
    "#file_name_lcs_1 = 'acs2-na.json'\n",
    "#file_name_lcs_2 = 'bacs-1.json'\n",
    "\n",
    "# A2 ) ACS2 and BACS-1 in non aliased environments with GA\n",
    "#file_name_lcs_1 = 'acs2-na-ga.json'\n",
    "#file_name_lcs_2 = 'bacs-1-ga.json'\n",
    "\n",
    "# B1 ) ACS2 and BACS-2 in aliased environments\n",
    "#file_name_lcs_1 = 'acs2.json'\n",
    "#file_name_lcs_2 = 'bacs-2.json'\n",
    "\n",
    "# B2 ) ACS2 and BACS-3 in aliased environments\n",
    "#file_name_lcs_1 = 'acs2.json'\n",
    "#file_name_lcs_2 = 'bacs-3.json'\n",
    "\n",
    "# B3 ) BACS-2 and BACS-3 in aliased environments\n",
    "file_name_lcs_1 = 'bacs-2.json'\n",
    "file_name_lcs_2 = 'bacs-3.json'\n",
    "\n",
    "# Font size et figuresize parameters for plotting\n",
    "figure_size = (20, 10)\n",
    "axe_label_fontsize = '28'\n",
    "tick_label_fontsize = '24'\n",
    "legend_fontsize = '24'\n",
    "\n",
    "# Significance level for p-values\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please, do not modify any lines of code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path, file_name_lcs_1, file_name_lcs_2):\n",
    "    json_data_from_lcs_1 = path + file_name_lcs_1\n",
    "    json_data_from_lcs_2 = path + file_name_lcs_2\n",
    "\n",
    "    with open(json_data_from_lcs_1) as json_file_1:\n",
    "        raw_data_from_lcs_1 = json.load(json_file_1)\n",
    "\n",
    "    with open(json_data_from_lcs_2) as json_file_2:\n",
    "        raw_data_from_lcs_2 = json.load(json_file_2)\n",
    "\n",
    "    raw_data = [raw_data_from_lcs_1,raw_data_from_lcs_2]\n",
    "    lcs_name = [json_data_from_lcs_1[offset_path:-5], json_data_from_lcs_2[offset_path:-5]]\n",
    "    return raw_data, lcs_name\n",
    "\n",
    "# Call function to prepare plotting data\n",
    "raw_data, lcs_name = read_json(path, file_name_lcs_1, file_name_lcs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing pandas plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pandas_plotting_data(raw_data, lcs_name):\n",
    "    cleaned_data = {\n",
    "        'LCS':[], \n",
    "        'Maze':[], \n",
    "        'Knowledge (%)':[],\n",
    "        'Population of classifiers':[], \n",
    "        'Reliable classifiers':[],\n",
    "        'Average steps to exit':[],\n",
    "        #'Mean realiable classifier specificity':[]\n",
    "    }\n",
    "    nb_of_environments = 0\n",
    "    for i in range(len(lcs_name)):\n",
    "        for item in raw_data[i]:\n",
    "            if 'time' not in item.keys():\n",
    "                nb_of_environments += 1\n",
    "                for idx in range(len(item['knowledge_list'])):\n",
    "                    cleaned_data['LCS'].append(lcs_name[i])\n",
    "                    if item['maze'][:-3] == \"Woods101demi\":\n",
    "                        cleaned_data['Maze'].append(\"Woods101.5\")\n",
    "                    else:\n",
    "                        cleaned_data['Maze'].append(item['maze'][:-3])\n",
    "                    cleaned_data['Knowledge (%)'].append(item['knowledge_list'][idx])\n",
    "                    cleaned_data['Population of classifiers'].append(item['population_list'][idx])\n",
    "                    cleaned_data['Reliable classifiers'].append(item['reliable_list'][idx])\n",
    "                    cleaned_data['Average steps to exit'].append(\n",
    "                        item['avg_exploit_rl_list'][idx]\n",
    "                    )\n",
    "                    #cleaned_data['Mean realiable classifier specificity'].append(\n",
    "                    #    item['mean_reliable_classifier_specificity_list'][idx]\n",
    "                    #)\n",
    "\n",
    "    nb_of_environments /= len(lcs_name)\n",
    "    pandas_data = pd.DataFrame(cleaned_data)\n",
    "    return nb_of_environments, pandas_data\n",
    "\n",
    "nb_of_environments, pandas_data = prepare_pandas_plotting_data(raw_data, lcs_name)\n",
    "pandas_data = pandas_data.sort_values('Maze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting boxplots with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc={\n",
    "    'axes.labelsize':axe_label_fontsize,\n",
    "    'xtick.labelsize':tick_label_fontsize,\n",
    "    'ytick.labelsize':tick_label_fontsize\n",
    "}\n",
    "sns.set(context='paper', style='ticks', rc=rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(pandas_data, Y, legend_loc):\n",
    "    \n",
    "    # Build the main figure\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    sns.stripplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        edgecolor='gray',\n",
    "        jitter=True,\n",
    "        linewidth = 1,\n",
    "        dodge=True,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        x = 'Maze',\n",
    "        y = Y,\n",
    "        hue = 'LCS',\n",
    "        data = pandas_data,\n",
    "        fliersize=0,\n",
    "        palette='pastel',\n",
    "        ax = ax\n",
    "    )\n",
    "\n",
    "    # Set up x tick labels and x label correctly\n",
    "    plt.xticks(rotation = 45, horizontalalignment = 'right')\n",
    "    plt.xlabel('')\n",
    "\n",
    "    # Hide the horizontal gridlines\n",
    "    ax.yaxis.grid(False)\n",
    "\n",
    "    # Show the vertical gridlines\n",
    "    ax.xaxis.grid(True)\n",
    "\n",
    "    # Shift major ticks to create column for each maze\n",
    "    plt.xticks(np.arange(nb_of_environments)+0.5)\n",
    "\n",
    "    # Set up minor ticks and align label of major ticks on minor ticks\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(0.5))\n",
    "    dx = (((figure_size[0] * 100 / 4.))/nb_of_environments - 10)/72.; dy = 0/72. # Width in inches converted into pixels depending on default DPI\n",
    "    offset = matplotlib.transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "    for label in ax.xaxis.get_majorticklabels():\n",
    "        label.set_transform(label.get_transform() - offset)\n",
    "\n",
    "    # Set up legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[0:2], labels[0:2], frameon=False, loc=legend_loc, fontsize=legend_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knowledge(pandas_data, zipped:bool=True):\n",
    "    plot_figure(pandas_data, Y='Knowledge (%)', legend_loc='lower right')\n",
    "    \n",
    "def plot_population(pandas_data, only_reliable:bool=False):\n",
    "    if not only_reliable:\n",
    "        Y = 'Population of classifiers'\n",
    "    else:\n",
    "        Y = 'Reliable classifiers'\n",
    "    plot_figure(pandas_data, Y=Y, legend_loc='upper right')\n",
    "\n",
    "def plot_ratio_reliable(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Ratio of reliable classifiers in population', legend_loc='upper right')\n",
    "\n",
    "def plot_mean_classifier_specificity(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Mean realiable classifier specificity', legend_loc='upper right')\n",
    "\n",
    "def plot_avg_steps_to_exit(pandas_data):\n",
    "    plot_figure(pandas_data, Y='Average steps to exit', legend_loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_knowledge(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_population(pandas_data, only_reliable=False)\n",
    "plot_population(pandas_data, only_reliable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_steps_to_exit(pandas_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing statistical data from raw read json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_by_env_name = {}\n",
    "for i in range(len(lcs_name)):\n",
    "    for item in raw_data[i]:\n",
    "        if 'time' not in item.keys():\n",
    "            if item['maze'] not in raw_list_by_env_name.keys():\n",
    "                raw_list_by_env_name[item['maze']] = {\n",
    "                    'knowledge_list' : [],\n",
    "                    'population_list' : [],\n",
    "                    'reliable_list' : [],\n",
    "                    'avg_exploit_no_rl_list' : [],\n",
    "                    'avg_exploit_rl_list' : [],\n",
    "                    #'mean_reliable_classifier_specificity_list' : []\n",
    "                }\n",
    "            raw_list_by_env_name[item['maze']]['knowledge_list'].append(\n",
    "                np.array(item['knowledge_list']))\n",
    "            raw_list_by_env_name[item['maze']]['population_list'].append(\n",
    "                np.array(item['population_list']))\n",
    "            raw_list_by_env_name[item['maze']]['reliable_list'].append(\n",
    "                np.array(item['reliable_list']))\n",
    "            #raw_list_by_env_name[item['maze']]['mean_reliable_classifier_specificity_list'].append(\n",
    "            #    np.array(item['mean_reliable_classifier_specificity_list']))\n",
    "            raw_list_by_env_name[item['maze']]['avg_exploit_rl_list'].append(\n",
    "                np.array(item['avg_exploit_rl_list']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_statistical_data = {\n",
    "    'Maze':[],\n",
    "    'Metric':[],\n",
    "    'Alternative':[],\n",
    "    'Degrees of freedom':[],\n",
    "    'P Value':[],\n",
    "    'Null Hypothesis':[]\n",
    "}\n",
    "for env_name in raw_list_by_env_name.keys():\n",
    "    for metric in raw_list_by_env_name[env_name].keys():\n",
    "        if metric != \"avg_exploit_no_rl_list\":\n",
    "            for i in range(3):\n",
    "                raw_statistical_data['Maze'].append(env_name)\n",
    "                raw_statistical_data['Metric'].append(metric)\n",
    "                x1 = np.array(raw_list_by_env_name[env_name][metric][0])\n",
    "                x2 = np.array(raw_list_by_env_name[env_name][metric][1])\n",
    "                if i == 0:\n",
    "                    alt = 'two-sided'\n",
    "                elif i == 1:\n",
    "                    alt = 'larger'\n",
    "                else:\n",
    "                    alt = 'smaller'\n",
    "                raw_statistical_data['Alternative'].append(alt)\n",
    "                tstats, pvalue, dof = stests.ttest_ind(x1, x2, alternative=alt, usevar='unequal', value=0)\n",
    "                raw_statistical_data['Degrees of freedom'].append(dof)\n",
    "                raw_statistical_data['P Value'].append(pvalue)\n",
    "                if pvalue<alpha:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Reject')\n",
    "                else:\n",
    "                    raw_statistical_data['Null Hypothesis'].append('Accept')\n",
    "statistical_pandas = pd.DataFrame(raw_statistical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_pandas.to_csv(path + lcs_name[0] + '_&_' + lcs_name[1] + '_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1 = []\n",
    "#mean = 2.75\n",
    "#for i in range(2):\n",
    "#    x1.append(mean)\n",
    "#x2 =  [2.706, 2.956, 2.736, 2.996, 2.832, 2.928, 2.84, 3.06, 2.72, 3.096, 2.894, 2.824, 2.978, 2.944, 2.754, 2.718, 2.798, 2.996, 2.792, 3.018, 2.986, 2.938, 2.796, 2.76, 2.852, 2.942, 2.784, 2.864, 2.844, 2.784]\n",
    "#tstats, pvalue, dof = stests.ttest_ind(x2, x1, alternative='two-sided', usevar='unequal', value=0)\n",
    "#print(x1)\n",
    "#print(x2)\n",
    "#print(tstats, pvalue, dof)\n",
    "#if pvalue<0.05:\n",
    "#    print('Reject')\n",
    "#else:\n",
    "#    print('Accept')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
